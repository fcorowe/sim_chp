---
# output: bookdown::github_document2
output:
  bookdown::pdf_document2:
    template: template.tex
    keep_tex: true
bibliography: sim_refs.bib
editor_options:
  markdown:
    wrap: sentence
---

Overall aim: To set our view about how the field of spatial interaction modelling should evolve.

Key argument: Spatial interaction models are great, yet, not progress has been made over the last two/three decades (though we should recognise the work LeSage on spatial econometrics, Dan Griffith on spatial filtering, Kanaroglou et al on spatial discrete choice modelling, radiation models).
Key challenges have prevented progress:

1\.
reproducibility

2\.
calibration <!--# AD - to elaborate this idea of calibration. I have long struggled with the term calibration in the context of spatial interaction modelling. In the olden days,  people used calibration to describe curve fitting parameters in a mathemathical framework. In a statistical context, I would understand this as the steps taken for a model to converge. -->

<!--# AD - sounds good - just testing by adding my own comment here and will try and commit and push now -->

3\.
large volumes of granular spatial data <!--# FR - my argument here is that up to recently we did not have the need to deal with large data sets capturing movement. I argue that this imposes two additional challenges: (1) need to capture heterogeneity/variability across different populations and places, and (2) need for new and scalable models (where machine learning and other modelling frameworks come in) -->.

Context: spatial interaction modelling in a world of big data, machine learning, open science, digital technology and uncertainty.

The text included here is for our own benefit.
The idea of challenges

# Definition and Uses

-   What are spatial interaction models?
    Spatial interaction models (SIMs) definition - first intuitive definition / explanation - conceptually describe what spatial interaction modelling is (including its key components - talk about unconstrained and constrained models. But I don't think we need to spend tons of words on this.

-   Why are SIMs important?
    Applications and context - what they allow us to do: retail (delineating market areas), migration, human mobility, transport (factors influencing the size of people travelling), urban planning (), what if scenarios (forecasting)

-   Progress on SIMs - recognise the work LeSage on spatial econometrics, Dan Griffith on spatial filtering, Kanaroglou et al on spatial discrete choice modelling, radiation models

-   Remaining challenges - reproducibility (technical infrastructure)

Objective of the section: To conceptually describe what spatial interaction modelling is (including its key components), how it is used, why it is important and how it relates to gravity modelling.
I conceive this section to provide a brief, gentle, intuitive introduction to spatial interaction models, emphasising its importance and the various context of applications of SIMs i.e. retail, population, transport, etc.

-   Mention of key SIM paradigms

<!--# FR: I would say let's introduce the intuition of traditional gravity models and then what progress has been made. -->

SIMs cover a wide range of methods and applications.
According to @rodrigue_geography_2013, there are 3 broad types of SIM:

-   Gravity models, in which interaction is estimated as a function of size/attractiveness of start/end points and some impedance function; this is the original and 'traditional' SIM.

-   Radiation models or 'potential models', in which interaction is estimated as a function of size/attractiveness of start/end points but mediated by a function of intervening opportunities [@simini_universal_2012].

-   Retail models, which seek to identify the 'market boundary' between economic hubs.

For the majority of this paper we will focus on gravity models.
There are four main types of traditional SIMs [@wilson_family_1971] :

-   Unconstrained

-   Production-constrained

-   Attraction-constrained

-   Doubly-constrained

The basic unconstrained SIM can be defined was follows, in a paper that explored many iterations on this formulation:

$$
T_{i j}=K \frac{W_{i}^{(1)} W_{j}^{(2)}}{c_{i j}^{n}}
$$ "where $T_{i j}$ is a measure of the interaction between zones $i$ and $W_{i}^{(1)}$ is a measure of the 'mass term' associated with zone $z_i$, $W_{j}^{(2)}$ is a measure of the 'mass term' associated with zone $z_j$, and $c_{ij}$ is a measure of the distance, or generalised cost of travel, between zone $i$ and zone $j$".
$K$ is a 'constant of proportionality' and $n$ is a parameter to be estimated.

Redefining the $W$ terms as $m$ and $n$ for origins and destinations respectively [@simini_universal_2012], this classic definition of the 'gravity model' can be written as follows:

$$
T_{i j}=K \frac{m_{i} n_{j}}{c_{i j}^{n}}
$$

Identify reproducibility, calibration and big data as key challenges as noted above.
If we frame these as key challenges, I think it would make sense to map the rest of the sections onto these challenges.
The issue I have on doing this is that the issues of calibration and big data may entail similar or the same challenges.

# Expanding spatial interaction modelling

Objective of the section: To discuss ways in which spatial interaction modelling can be expanded.
I am particularly interested in advocating for (1) seeing spatial interaction models in a context of uncertainty, rather than as mathematical models; and, (2) discussing how hierarchical / generalised linear mixed modelling can offer ways to capture variability across places and populations.

# Reproducible SIMs <!--# RL to lead -->

*Objective of the section: To discuss the opportunities and challenges of estimating spatial interacting modelling in the context of reproducible research*

<!--# FR: I think this is good . The only suggestion I would make is to make this a bit broader to encapsulate the ideas of open science and enabling infrastructure. I see open science as a key enabler of reproducibility. As you identified in the text, there are options to fit SIMs but these options are commercial and not widely available, and are not fully transparent. It is challenging to know how SIMs are estimated, and therefore difficult to replicate. Also I would use the concept of enabling infrastructure because I see software as one of the components enabling the development of reproducible SIMs, but I don't think it is the only one. Again, as you wuite rightly identied below, practical tutorials to be able to apply SIMs are lacking. The work by Adam is probably an exception. Tutorials tend to focus on the theory, but the jump from the theory to the application of SIMs is quite dramatic. People often struggle to see the switch from an origin-destination matrix to a vector of origin-destination pair of flows -->

Reproducibility has not been prominent in research developing and using SIMs outlined in the previous sections.
This is understandable, because computer hardware, software and know-how needed to develop and run SIMs was simply unavailable to most people (let alone lowly and often cash-strapped students!) for most of field's history.
Even when consumer laptops became widely available and more affordable during the 2000s, there were few well-known user-friendly off-the-shelf options implementing SIMs other than MATLAB and arguably Excel, unless you were willing to dive into programming.

Fast-forward to the 2020s and computer hardware, and perhaps more importantly software, is much easier to obtain.
In terms of affordability, a second-hand laptop whose processing power would have been considered a supercomputer by 1990s standards (and impossibly powerful when seminal SIM papers were published) can be obtained for around \$100 dollars in most countries.[^1]
Tutorials teaching you to code with popular languages for data science abound, with R and Python particularly prominent in the fields (including Quantitative Geography, Social Physics, Statistics and more recently Urban Analytics) where much SIM research is undertaken.
It has never been easier to write reproducible code implementing SIMs yet, despite notable exceptions [@dennett_modelling_2018], most SIMs and the findings they produce, are not reproducible.

[^1]: See <https://ebay.com/b/Laptops-Netbooks/175672/bn_1648276> for an example of the huge international market for second-hand laptops.

One could argue that reproducibility is a 'nice to have', an optional and potentially onerous extra thing to think about during the research process.
Yet increasingly it is becoming apparent that reproducibility is *vital* for research to be falsifiable [@popper_logic_1934] and therefore scientifically sound.
In this broader context, reproducibility is a "challenge to adjust scholarly communication to today's level of digitisation and diversity of scientific outputs" [@nust_practical_2021].
A key message in our manifesto for SIM research in the 2020s, therefore, is for the models to be open and the results they create to be reproducible using published code and data (example synthetic data when the raw data cannot be published).
We urge readers implementing SIMs to make their work reproducible not only for philosophical reasons.
There are tangible benefits of making your SIM work reproducible:

-   People are more likely to cite your work if they can reproduce it.

-   Reproducible results based on open source software discourages reinvention of wheels and associated wasting of time.

-   Reproducible research encourages innovation, both of your work and the work of others, because you can focus on what is new and novel rather than (for example) writing a paper implementing an existing SIM in a slightly new context (as many SIM papers have).

To highlight the ease with which reproducible SIMs can now be developed, we present below reproducible R code that implements a simple SIM.
It is notable that open source software continues to evolve: the code presented below uses the `simodels` R package, the development of which was partly motivated by this book chapter (the primary motivation was the need to develop SIMs to represent trips for purposes other than commuting and travel to school in Ireland as part of a contract with Transport Infrastructure Ireland, highlighting the applied nature of SIM research).
`simodels` enables to develop SIMs starting with geographic datasets in fewer lines of code than was possible a few years ago [@dennett_modelling_2018].
Naturally, the starting point is to install the package (and R and a modern IDE such as RStudio or [VS Code](https://marketplace.visualstudio.com/items?itemName=REditorSupport.r) if the software is not already installed on your computer), with the following lines of code: <!--# Hopefully we can replace the second line below with # install.packages("simodels") before the chapter is published! -->

```{r, eval=FALSE}
install.packages("simodels")
```

The package installed with the previous command, which is called `simodels` (short for spatial interaction models) does not just provide functions for running and fitting (finding parameters to minimise model-observation differences): it provides a framework for developing SIMs and creating new functions implementing different types of SIM and using a variety of pre-existing modelling tools in SIMs.
We will also install `tidyverse` (if not already) for intuitive data processing functionality, and load (technically attach) the packages so their functions are available:

```{r, eval=FALSE}
install.packages("tidyverse")
```

```{r, message=FALSE}
library(simodels)
library(tidyverse)
```

The starting 'point' (pun intended!) of all SIMs is geographic entities representing trip start, end or (for 'multi-partite' models) or intermediate points.
We use the word 'features' because almost all SIMs use input datsets that are compliant with the 'simple features' open specification [@ogcopengeospatialconsortiuminc_opengis_2011], typically imported from files encoded in proprietary the Shapefile (`.shp`) or open GeoPackage (`.gpkg`), GeoJSON (`.geojson`) or other geographic file formats.
R has a mature ecosystem for working with geographic file formats, so we can use existing function for this data import stage, using the `sf` package:

```{r urls}
u_origins = "origin_zones.geojson"
f_origins = basename(u_origins)
u_destinations = "destination_points.geojson"
f_destinations = basename(u_destinations)
```

```{r, eval=FALSE}
download.file(u_origins, destfile = f_origins)
download.file(u_destinations, destfile = f_destinations)
```

```{r, echo=FALSE, eval=FALSE}
pubs_example = si_pubs %>% 
  filter(grepl(pattern = "Chemic|Nag", x = name)) %>% 
  transmute(name, size = c(100, 80))
origin_zones = si_zones %>% 
  mutate(to_pubs = round(all / runif(nrow(si_zones), min = 30, max = 70)) ) %>% 
  select(geo_code, to_pubs) 
origin_centroids = sf::st_centroid(origin_zones)
pubs_example_5km = sf::st_buffer(pubs_example, 5000)
origin_centroids_to_keep = origin_centroids[pubs_example_5km, ]
origin_zones = origin_zones %>% 
  filter(geo_code %in% origin_centroids_to_keep$geo_code)
sf::write_sf(origin_zones, "origin_zones.geojson", delete_dsn = TRUE)
sf::write_sf(pubs_example, "destination_points.geojson", delete_dsn = TRUE)
```

```{r}
origin_zones = sf::read_sf("origin_zones.geojson")
destination_points = sf::read_sf("destination_points.geojson")
```

The code chunk above demonstrates importing specific data objects:

-   A simple features object with 'multipolygon' geometries representing administrative zones that constitute trip origins in the subsequent reproducible SIMs.

-   Another simple features object with 'point' geometries representing two popular pubs in Leeds that are trip destinations in the SIMs below.

Before creating SIMs representing travel to these two pubs in Leeds, a deliberately minimal and simple input dataset to aid understanding, it is worth doing a small amount of exploratory data analysis (EDA) to check the input datasets.
This is undertaken with the following commands:

```{r, out.width="50%", fig.show='hold'}
origin_zones %>% 
  ggplot() +
  geom_histogram(aes(x = to_pubs), binwidth = 10)
origin_zones %>% 
  ggplot() +
  geom_sf(aes(fill = to_pubs), alpha = 0.5) +
  geom_sf(data = destination_points)
```

```{r, echo=FALSE, eval=FALSE}
plot(sf::st_geometry(origin_zones))
plot(sf::st_geometry(destination_points), pch = 15, add = TRUE)
```

For many applications the most important function in the `simodels` package as `si_to_od()`, as demonstrated below:

```{r}
od_zones_to_points = si_to_od(origin_zones, destination_points)
class(od_zones_to_points)
nrow(od_zones_to_points)
names(od_zones_to_points)
```

As shown in the output above, the result is a data frame with 94 rows (representing the full combination of trips from every one of the 47 origin zone to each of the 2 destinations).
The names of the data frame refer to variables for each origin and each destination.
When working on large input datasets, this 'full matrix' of combinations can get unhelpfully large: an OD dataset from every MSOA to every pub in England, for example, would results in a dataset with `r format(7000 * 50000, big.mark = ",", scientific = FALSE)` (350 million) rows, for example.
To reduce dataset sizes, by orders of magnitude in some cases, the 'sparse matrix' representing only OD pairs below a certain distance threshold can be created instead of the full matrix, by adding a `max_dist` argument as follows, which sets the maximum Euclidean distance between zone centroids and point destinations to be included in the OD dataset at 5 km in this case:

```{r}
od_zones_to_points = si_to_od(origin_zones, destination_points, max_dist = 5000)
nrow(od_zones_to_points)
```

This updated OD dataset is only a bit smaller (79 rows compared with 94 rows previously) of the size of the original because the example dataset is samll but in other cases setting a maximum distance can greatly speed-up SIM processing, modelling and visualisation run times in cases where you are happy to treat trips more than a threshold distance as negligible (in the case of trips to pubs 5 km is probably reasonable for distances to 'the local' pub in urban areas but the distance threshold should be based on evidence where possible).

From this point, we can specific a SIM model as a function as follows:

```{r}
gravity_model = function(beta, d, m, n) {
  m * n * exp(-beta * d / 1000)
} 
```

and implement it with the following command:

```{r}
od_to_pubs_result = od_zones_to_points %>% 
  si_calculate(fun = gravity_model, 
               m = origin_to_pubs,
               n = destination_size,
               d = distance_euclidean,
               beta = 0.5,
               constraint_production = origin_to_pubs)
```

We can check the results as follows:

```{r}
sum(od_to_pubs_result$interaction)
sum(origin_zones$to_pubs)
```

As shown above, the total number of trips is the same in the OD data as in the zone level data.
We can visualise the result as follows, resulting in Figure \@ref(fig:pubresmap):

```{r pubresmap, message=FALSE, fig.cap="Results of a reproducible SIM undertaken on a minimal example based on synthetic data representing hypothetical trips to 2 pubs in Leeds, UK."}
library(ggspatial)
# rosm::osm.types()
od_to_pubs_result %>% 
  ggplot() +
  annotation_map_tile(type = "cartolight") +
  geom_sf(aes(lwd = interaction, colour = D), alpha = 0.5) +
  scale_size_continuous(range = c(0.3, 3)) +
  geom_sf(data = origin_zones, fill = NA, lty = 2, alpha = 0.5) +
  theme_void()
```

```{r, echo=FALSE, eval=FALSE}
# commented out as not helpful result: we would need more destinations for this to be useful:
od_to_pubs_result %>% 
  ggplot() +
  geom_point(aes(distance_euclidean, interaction, colour = D))
```

# Spatial interaction modelling using machine learning

Objective of the section: To discuss how machine learning can enhance flow count inference and prediction

# Facilitating future progress of spatial interaction modelling

Objective of the section: To identify and discuss the key pillars that will enable progress on all the proposed fronts - open science, important and new questions and digital infrastructure.
I see this as our conclusion - probably one or two short paragraph summarising what has been discussed with a forward looking approach.

# References
